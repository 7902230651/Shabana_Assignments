{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8345941a-4efb-4c61-a7ba-a1e21060e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the train data\n",
    "train_data = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\train_LZdllcl.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "train_data['previous_year_rating'] = train_data['previous_year_rating'].fillna(train_data['previous_year_rating'].mean())\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "train_data = pd.get_dummies(train_data, columns=['department', 'region', 'education', 'gender', 'recruitment_channel'])\n",
    "\n",
    "# Select features and target\n",
    "train_features = train_data.drop('avg_training_score', axis=1)\n",
    "train_target = train_data['avg_training_score']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "058974f2-66b2-477e-bdde-8a1577287379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_data = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\test_2umaH9m.csv\")\n",
    "\n",
    "# Handle missing values in the test data\n",
    "test_data['previous_year_rating'] = test_data['previous_year_rating'].fillna(test_data['previous_year_rating'].mean())\n",
    "\n",
    "# One-hot encode categorical columns in the test data\n",
    "test_data = pd.get_dummies(test_data, columns=['department', 'region', 'education', 'gender', 'recruitment_channel'])\n",
    "\n",
    "# Ensure the test data has the same columns as the training data\n",
    "missing_cols = set(train_features.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    test_data[col] = 0\n",
    "test_data = test_data[train_features.columns]\n",
    "\n",
    "# Scale the test data\n",
    "test_features_scaled = scaler.transform(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "139b9729-f42e-4c7e-952e-bead391b4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features_scaled, train_target, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf9c8a50-bda2-4064-a51b-d4e60acb8e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'copy_X': True, 'fit_intercept': True, 'n_jobs': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the corrected parameter grid\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'n_jobs': [None, -1]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "try:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters:\", best_params)\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    best_model = LinearRegression(**best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "except ValueError as e:\n",
    "    print(\"Error during model fitting:\", e)\n",
    "    best_model = LinearRegression()\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c8b3b61-26f4-4e5d-b229-59d833c3d23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE after tuning: 16.62078173686298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = best_model.predict(X_val)\n",
    "print(\"Validation MSE after tuning:\", mean_squared_error(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b78cfbb9-31c7-4fa4-968b-14c1979d38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_model.predict(test_features_scaled)\n",
    "test_predictions = (test_predictions > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee2688cd-44fb-4beb-aab4-272122783ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample submission file\n",
    "submission = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\sample_submission_M0L0uXE.csv\")\n",
    "\n",
    "# Update the submission file with predictions\n",
    "submission['is_promoted'] = test_predictions\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('final_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6774107f-e4db-4410-bac2-b3f3f0853b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78bca934-4e33-456a-b8d1-634620f8c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       employee_id  is_promoted\n",
      "0             8724            1\n",
      "1            74430            1\n",
      "2            72255            1\n",
      "3            38562            1\n",
      "4            64486            1\n",
      "...            ...          ...\n",
      "23485        53478            1\n",
      "23486        25600            1\n",
      "23487        45409            1\n",
      "23488         1186            1\n",
      "23489         5973            1\n",
      "\n",
      "[23490 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "imported_df = pd.read_csv('final_submission.csv')\n",
    "print(imported_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69e49836-700c-422b-bab9-dc063bcee06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.anaconda', '.conda', '.condarc', '.continuum', '.ipynb_checkpoints', '.ipython', '.jupyter', '.matplotlib', '.ms-ad', '1.ipynb', '3D Objects', 'anaconda3', 'AppData', 'Application Data', 'Assignment on Classification.ipynb', 'Assignment on Clustering.ipynb', 'Bank Account Manager.ipynb', 'Conditional Statements.ipynb', 'Contacts', 'Cookies', 'Correlation.ipynb', 'DATA STRUCTURES.ipynb', 'Documents', 'Downloads', 'Encoding.ipynb', 'Favorites', 'Feature Engineering.ipynb', 'final_submission.csv', 'Handling missing values.ipynb', 'IntelGraphicsProfiles', 'Intermediate assessment 1.ipynb', 'Intermediate assessment 2.ipynb', 'Linear Regression.ipynb', 'Links', 'Local Settings', 'Matplotlib and Seaborn.ipynb', 'Microsoft', 'MicrosoftEdgeBackups', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{15a0d507-20cb-11ef-b887-e02c70fcce20}.TM.blf', 'NTUSER.DAT{15a0d507-20cb-11ef-b887-e02c70fcce20}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{15a0d507-20cb-11ef-b887-e02c70fcce20}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'NumPy.ipynb', 'OneDrive', 'Outlier Detection.ipynb', 'Pandas.ipynb', 'Polynomial Regression.ipynb', 'PRACTICE.ipynb', 'Preprocessing Assignment.ipynb', 'PrintHood', 'Python for DS assignment.ipynb', 'Reading data from different sources.ipynb', 'Recent', 'Saved Games', 'Scaling.ipynb', 'Searches', 'SendTo', 'Start Menu', 'Templates', 'Tracing', 'Untitled.ipynb', 'Untitled1.ipynb', 'Untitled2.ipynb', 'Untitled3.ipynb', 'Untitled4.ipynb', 'Videos', 'Weather Data Analyzer.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c666ee-cbf8-4915-80c8-848a67f5a8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
